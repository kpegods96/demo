---
title: "Course Demonstrations"
author: "Lifetime Physical Activity Training"
date: "2025-09-09"
output: 
  html_document:
    self_contained: true
    toc: true
    toc_float: true
---

```{=html}
<style>
.copy-button {
  float: right;
  margin-top: -9px;
  margin-right: 10px;
  font-size: 0.8em;
  padding: 2px 6px;
  border: 1px solid #aaa;
  border-radius: 4px;
  background: #f8f8f8;
  cursor: pointer;
}
.copy-button:hover {
  background: #eee;
}
</style>
```

```{=html}
<script>
document.addEventListener("DOMContentLoaded", function() {
  document.querySelectorAll("pre code").forEach(function(codeBlock) {
    var button = document.createElement("button");
    button.className = "copy-button";
    button.type = "button";
    button.innerText = "Copy";

    button.addEventListener("click", function() {
      navigator.clipboard.writeText(codeBlock.innerText).then(function() {
        button.innerText = "Copied!";
        setTimeout(function() {
          button.innerText = "Copy";
        }, 2000);
      });
    });

    var pre = codeBlock.parentNode;
    if (pre.parentNode.classList.contains("sourceCode")) {
      pre.parentNode.insertBefore(button, pre);
    } else {
      pre.insertBefore(button, codeBlock);
    }
  });
});
</script>
```

------------------------------------------------------------------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Compilations of Course Demonstrations

This is a simple document that contains all the practical demonstrations you will find in the Systematic Review and Meta - Analysis Course. Click on the copy button at the left corner of each of the cells to copy the codes. Paste the codes in you R studio in order to also reproduce the similar outcome.

## Lecture 3.1 Demonstration

This is an set of r code for applying mean imputation, Last Observation Carried Forward (LOCF), and multiple imputation using a simulated dataset with missing values.

***Install the following packages if not already installed***

install.packages(c("mice", "zoo", "dplyr"))

mice - For multiple imputation

zoo - For LOCF

dplyr - For data manipulation

```{r, echo=TRUE}
library(mice) 
library(zoo) 
library(dplyr)    
```

**Simulate Dataset with Missing Values**

Here we are going to stimulate a sample dataset. But you can import your own dataset at this point if you have a dataset in this regard.

**Note:** the NA means missing data

```{r, echo=TRUE}
set.seed(123)
data <- data.frame(
  ID = 1:10,
  Age = c(25, 30, NA, 45, 50, NA, 60, 65, 70, NA),
  BP  = c(120, NA, 130, 135, NA, 140, 145, NA, 150, 155)
)

```

**Print the dataset for a visual inspection**

```{r, echo=TRUE}
print(data)
```

**Mean Imputation**

Impute missing values with column means

```{r, echo=TRUE}
data_mean_imp <- data %>%
  mutate(
    Age = ifelse(is.na(Age), mean(Age, na.rm = TRUE), Age),
    BP  = ifelse(is.na(BP), mean(BP, na.rm = TRUE), BP)
  )

```

**After Mean Imputation:**

```{r, echo=TRUE}
print(data_mean_imp)
```

**Last Observation Carried Forward (LOCF)**

Apply LOCF for each column

```{r, echo=TRUE}
data_locf <- data %>%
  mutate(
    Age = na.locf(Age, na.rm = FALSE),
    BP  = na.locf(BP, na.rm = FALSE)
  )

```

**After LOCF Imputation:**

```{r, echo=TRUE}
print(data_locf)
```

**Multiple Imputation (Using mice)**

Perform multiple imputation

```{r, echo=TRUE}
imp <- mice(data, m = 5, method = 'pmm', seed = 500)

```

**Check imputed data**

```{r, echo=TRUE}
summary(imp)

```

**Complete the first imputed dataset**

```{r, echo=TRUE}
data_mice <- complete(imp, 1)
```

**After Multiple Imputation (First Dataset):**

```{r, echo=TRUE}
print(data_mice)
```

## Lecture 3.2 Demonstration

This demonstration is on exploring heterogeneity in meta - analysis.

**Load the required package**

```{r, echo=TRUE}
library(metafor)
```

**Simulating 10 studies with random true effects + sampling error**

```{r, echo=TRUE}
set.seed(123) 
k <- 10
true_effects <- rnorm(k, mean = 0.3, sd = 0.2)  # true effects vary across studies
se <- runif(k, min = 0.08, max = 0.20)          # random standard errors
observed_effects <- rnorm(k, mean = true_effects, sd = se)

```

**Put into a dataframe**

```{r, echo=TRUE}
data <- data.frame(
  study_id = paste0("Study_", 1:k),
  effect_size = observed_effects,
  se = se
)

```

**Print data**

```{r, echo=TRUE}
print(data)
```

**Random-effects meta-analysis**

```{r, echo=TRUE}
res <- rma(yi = effect_size, sei = se, data = data, method = "REML")
```

**Summary of results**

```{r, echo=TRUE}
summary(res)
```

**Extract heterogeneity statistics**

```{r, echo=TRUE}
Q <- res$QE
Q_pval <- res$QEp
I2 <- res$I2
H2 <- res$H2

cat("Cochran's Q =", Q, "with p-value =", Q_pval, "\n")
cat("I-squared =", I2, "%\n")
cat("H-squared =", H2, "\n")

```

**Forest plot**

```{r, echo=TRUE}
forest(res, slab = data$study_id)
```

## Lecture 3.3 Demonstration

This demonstration highlights effect size calculation for meta - analysis

**Loading required library**

Note that you will have to install the package before loading it.

```{r, echo=TRUE}
library(meta)
```

**Load the sample dataset**

You can simply load the dataset using this line of code

***sample1 \<- Module_3C_sample1***

```{r, echo=TRUE}
sample1 <- data.frame(
  study = c("study1", "study2", "study3", "study4", "study5"),
  m1 = c(47, 49, 49, 47, 49),
  s1 = c(11, 11, 14, 10, 11),
  n1 = c(60, 65, 40, 200, 50),
  m2 = c(46, 46, 44, 41, 44),
  s2 = c(10, 11, 13, 9, 11),
  n2 = c(60, 65, 40, 200, 45)
)
```


**Calculate the effect size**

```{r, echo=TRUE}
meta1 <- metacont(n1, m1, s1, n2, m2, s2, sm="SMD", study, data=sample1)
meta1
```

**Forest plot**

```{r, echo=TRUE}
forest(meta1, digits.mean=0, digits.sd=0, fontsize = 6) # Default forest plot

```

## Lecture 4.1 Demonstration

This demonstration will highlight data cleaning before embarking on any further meta - analysis. In this demonstration, we will delete missing data instead of imputation methods emplored in Lecture 3.1.

**Load data**

Here we are going to generate the sample dataset using r codes. But you can import the dataset directly and follow along with the demonstration or use this approach.

```{r, echo=TRUE}
sample2 <- data.frame(
  Study_ID = c("S1", "S2", "S3", "S4", "S5"),
  Effect_Size = c(0.23, 0.45, NA, 0.67, 0.34),
  Variance = c(0.05, 0.07, 0.06, NA, 0.04),
  Sample_Size = c(100, 150, 120, 130, 200),
  Intervention_Type = c("A", "B", "A", "B", "A")
)
```

**Print original dataset**

```{r, echo=TRUE}
print(sample2)
```

**Load required library**

```{r, echo=TRUE}
library(dplyr)
```

**Load required library**

```{r, echo=TRUE}
df_clean <- sample2 %>%
  # Remove rows with missing effect sizes or variances
  filter(!is.na(Effect_Size), !is.na(Variance))

# This ensures meta-analysis models run correctly without errors
```

**Structuring variables**

```{r, echo=TRUE}
df_clean <- df_clean %>%
  mutate(Intervention_Type = factor(Intervention_Type))
```

**Print cleaned dataset**

```{r, echo=TRUE}
print(df_clean)
```

## Lecture 4.2 Demonstration

This demonstration focuses on how to generate pooled prevalence from group of studies.

**Load data**

```{r, echo=TRUE}
data <- data.frame(
  study = c("Umeh & Nkombua, 2018", "Shiriyedeve et al., 2019", "Peter et al., 2022", "Oyewole et al., 2014", "Oyeyemi et al., 2013", "Dimore et al., 2023", "Wonde et al., 2022","Banson et al., 2023","Mwimo et al., 2021","Edmealem et al., 2020", "Adeniyi et al., 2014", "Taylor et al., 2023", "Oyewole et al., 2015", "Enyew et al., 2023", "Nti et al., 2016", "Adeniyi et al., 2016"),
  events = c(53, 77, 83, 82, 641, 54, 173, 46, 307, 222, 62, 39, 82, 210, 40, 92),
  sample_size = c(150, 170, 131, 119, 934, 305, 368, 84, 325, 332, 122, 97, 119, 302, 120, 185),
  country = c("South Africa", "Botswana", "Ghana", "Nigeria", "Nigeria", "Ethiopia", "Ethiopia", "Ghana","Tanzania", "Ethiopia", "Nigeria", "Ghana", "Nigeria", "Ethiopia", "Ghana", "Nigeria")
)
```

**Calculate prevalence and 95%CI for each study**

```{r, echo=TRUE}
data$prevalence <- data$events / data$sample_size
data$lower_CI <- data$prevalence - 1.96 * sqrt((data$prevalence * (1 - data$prevalence)) / data$sample_size)
data$upper_CI <- data$prevalence + 1.96 * sqrt((data$prevalence * (1 - data$prevalence)) / data$sample_size)

```

**Meta - analysis for pooled prevalence**

```{r, echo=TRUE}
meta_analysis <- metaprop(
  event = data$events,              # Number of events (cases)
  n = data$sample_size,             # Sample size for each study
  studlab = data$study,             # Study labels
  comb.fixed = FALSE,                # Fixed-effect model
  comb.random = TRUE,               # Random-effects model
  sm = "PLOGIT"                     # Use logit transformation for prevalence
)

```

**Print cleaned dataset**

```{r, echo=TRUE}
forest(meta_analysis,
       studlab = TRUE,
       xlab = "Proportion",
       leftcols = c("studlab", "event", "n"),
       leftlabs = c("Study", "Physically Active", "Sample Size"),
       rightlabs = c("Weight"),
       col.diamond = "blue",
       col.predict = "darkgreen",
       fontsize = 8)

```

## Lecture 4.3 Demonstration

This demonstration focuses analyzing continuous data in studies comparing two groups before and after an intervention.

**Load required library**

```{r, echo=TRUE}
library(metafor)
```

**Load data**

```{r, echo=TRUE}
data <- data.frame(
  study = paste("Study", 1:5),
  m_pre_treat = c(50, 45, 60, 55, 52),
  m_post_treat = c(60, 50, 70, 63, 59),
  sd_pre_treat = c(10, 12, 11, 13, 12),
  sd_post_treat = c(9, 11, 10, 12, 11),
  n_treat = c(30, 28, 32, 25, 29),
  m_pre_control = c(51, 46, 61, 54, 53),
  m_post_control = c(52, 47, 62, 55, 54),
  sd_pre_control = c(9, 10, 10, 11, 10),
  sd_post_control = c(8, 9, 9, 10, 9),
  n_control = c(30, 28, 31, 26, 28)
)

```

**Calculate mean change and SD for each group**

```{r, echo=TRUE}
data$mean_change_treat <- data$m_post_treat - data$m_pre_treat
data$mean_change_control <- data$m_post_control - data$m_pre_control

```

**Pooled SD**

```{r, echo=TRUE}
data$pooled_sd <- sqrt(((data$n_treat - 1) * data$sd_post_treat^2 +
                        (data$n_treat - 1) * data$sd_pre_treat^2 +
                        (data$n_control - 1) * data$sd_post_control^2 +
                        (data$n_control - 1) * data$sd_pre_control^2) /
                        (2 * (data$n_treat + data$n_control - 2)))


```

**Effect size (Cohen's d)**

```{r, echo=TRUE}
data$es <- (data$mean_change_treat - data$mean_change_control) / data$pooled_sd

```

**Standard error**

```{r, echo=TRUE}
data$se <- sqrt((2 / data$n_treat) + (2 / data$n_control))

```

**Run meta-analysis**

```{r, echo=TRUE}
res <- rma(yi = data$es, sei = data$se, method = "REML", data = data)

```

**Summary**

```{r, echo=TRUE}
summary(res)

```

**Forest Plot**

```{r, echo=TRUE}
forest(res, slab = data$study)

```

## Lecture 4.4 Demonstration

This demonstration focuses analyzing continuous data from a single group before and after an intervention.

**Load required library**

```{r, echo=TRUE}
library(metafor)
```

**Load data**

```{r, echo=TRUE}
data <- data.frame(
  study = paste("Study", 1:5),
  m_pre = c(50, 55, 52, 60, 58),
  m_post = c(60, 62, 58, 66, 64),
  sd_pre = c(10, 12, 11, 13, 12),
  sd_post = c(9, 11, 10, 12, 11),
  n = c(30, 28, 32, 25, 29)
  
)

```

**Assume a pre-post correlation (e.g., 0.7)**

```{r, echo=TRUE}
r = 0.7
```

**Calculate standardized mean change using Morris & DeShon (2002) method**

```{r, echo=TRUE}
data$sd_diff <- sqrt(data$sd_pre^2 + data$sd_post^2 - 2 * r * data$sd_pre * data$sd_post)
data$mean_diff <- data$m_post - data$m_pre
data$smc <- data$mean_diff / data$sd_diff
data$var_smc <- (1 / data$n) + (data$smc^2 / (2 * data$n))
```

**Run meta-analysis**

```{r, echo=TRUE}
res <- rma(yi = smc, vi = var_smc, data = data, method = "REML")
```

**Summary**

```{r, echo=TRUE}
summary(res)
```

**forest Plot**

```{r, echo=TRUE}
forest(res, slab = data$study, xlab = "Standardized Mean Change")
```

## Lecture 4.5 Demonstration

This demonstration focuses analyzing binary data in a post-test-only design. In this type of study, outcomes are measured only after the intervention, making it a common approach when baseline data are unavailable.

**Load required library**

```{r, echo=TRUE}
library(metafor)
```

**Load data**

```{r, echo=TRUE}
data <- data.frame(
  Study = c("A", "A", "B", "B", "C", "C"),
  Group = c("Control", "Treatment", "Control", "Treatment","Control", "Treatment"),
  Events = c(10, 20, 5, 18, 12, 25),
  Total = c(100, 100, 80, 90, 110, 100)
)

```

**Reshape data**

```{r, echo=TRUE}
library(dplyr)
wide_data <- data %>%
  tidyr::pivot_wider(names_from = Group, values_from = c(Events, Total))

```

**Meta-analysis using odds ratio**

```{r, echo=TRUE}
meta_result <- metabin(
  event.e = wide_data$Events_Treatment,
  n.e = wide_data$Total_Treatment,
  event.c = wide_data$Events_Control,
  n.c = wide_data$Total_Control,
  studlab = wide_data$Study,
  sm = "OR",  # OR = Odds Ratio, use "RR" for Risk Ratio
  method = "Inverse", 
  method.tau = "DL", # DerSimonian-Laird for random effects
  comb.fixed = TRUE,
  comb.random = TRUE,
  fontsize = 8
)

```

**Print summary**

```{r, echo=TRUE}
summary(meta_result)

```

**Forest plot**

```{r, echo=TRUE}
forest(meta_result,
       xlab = "Odds Ratio (95% CI)",
       leftcols = c("studlab", "event.e", "n.e", "event.c", "n.c"),
       leftlabs = c("Study", "Events (Treatment)", "N (Treatment)",
                    "Events (Control)", "N (Control)"),
       col.diamond = "blue",
       col.predict = "darkgreen",
       fontsize = 5   # <-- set font size here
)

```

**Funnel plott**

```{r, echo=TRUE}
funnel(meta_result)

```


## Lecture 5.2 Demonstration

This demonstration focuses running funnel plot using R.

**Load required library**

```{r, echo=TRUE}
library(metafor)
```

**Load data**

```{r, echo=TRUE}
data <- data.frame(
  Study = c("Study 1", "Study 2", "Study 3", "Study 4", "Study 5", "Study 6", "Study 7", "Study 8", "Study 9", "Study 10"),
  Effect_Size = c(0.2, 0.5, 0.3, 0.7, 0.4, 0.6, 0.9, 0.8, 0.55, 0.45),
  Standard_Error = c(0.1, 0.15, 0.12, 0.2, 0.18, 0.1, 0.25, 0.22, 0.14, 0.16)
)

```


**Run a random effect model**

```{r, echo=TRUE}
res <- rma(yi = Effect_Size, sei = Standard_Error, data = data, method = "REML")
```



**Generate the funnel Plot**

```{r, echo=TRUE}
funnel(res, main = "Funnel Plot for Publication Bias")
```

## Lecture 5.3 Demonstration

This demonstration focuses running egger's test using R.

**Load required library**

```{r, echo=TRUE}
library(metafor)
```

**Load data**

```{r, echo=TRUE}
proportions <- c(0.35, 0.45, 0.63, 0.69, 0.69, 0.18, 0.47, 0.55, 0.94, 
                 0.67, 0.51, 0.40, 0.69, 0.70, 0.33, 0.50)  
n <- c(150, 170, 131, 119, 934, 305, 368, 84, 325, 332, 
       122, 97, 119, 302, 120, 185)

# Convert proportions to counts (events)
events <- round(proportions * n)

```

**Compute effect sizes: log odds ratios (logit transformed proportions)**

```{r, echo=TRUE}
escalc_data <- escalc(measure = "PLO", xi = events, ni = n)
```


**Running a random effect model**

```{r, echo=TRUE}
res <- rma(yi, vi, data = escalc_data, method = "REML")
```


**Egger's regression test for funnel plot asymmetry**

```{r, echo=TRUE}
egger_test <- regtest(res, model = "rma")
```

**Print egger's test results**

```{r, echo=TRUE}
print(egger_test)
```


## Lecture 5.5 Demonstration

This demonstration focuses running sub-group analysis using R.

**Load required library**

```{r, echo=TRUE}
library(meta)
```

**Load data**

```{r, echo=TRUE}
data <- data.frame(
  study = c("Umeh & Nkombua, 2018", "Shiriyedeve et al., 2019", "Peter et al., 2022", "Oyewole et al., 2014", "Oyeyemi et al., 2013", "Dimore et al., 2023", "Wonde et al., 2022","Banson et al., 2023","Mwimo et al., 2021","Edmealem et al., 2020", "Adeniyi et al., 2014", "Taylor et al., 2023", "Oyewole et al., 2015", "Enyew et al., 2023", "Nti et al., 2016", "Adeniyi et al., 2016"),
  events = c(53, 77, 83, 82, 641, 54, 173, 46, 307, 222, 62, 39, 82, 210, 40, 92),
  sample_size = c(150, 170, 131, 119, 934, 305, 368, 84, 325, 332, 122, 97, 119, 302, 120, 185),
  country = c("South Africa", "Botswana", "Ghana", "Nigeria", "Nigeria", "Ethiopia", "Ethiopia", "Ghana","Tanzania", "Ethiopia", "Nigeria", "Ghana", "Nigeria", "Ethiopia", "Ghana", "Nigeria")
)

```


**Calculating prevalence and 95% CI**

```{r, echo=TRUE}
data$prevalence <- data$events / data$sample_size
data$lower_CI <- data$prevalence - 1.96 * sqrt((data$prevalence * (1 - data$prevalence)) / data$sample_size)
data$upper_CI <- data$prevalence + 1.96 * sqrt((data$prevalence * (1 - data$prevalence)) / data$sample_size)

```


**Meta-analysis with sub-group (moderator) by country**

```{r, echo=TRUE}
meta_analysis <- metaprop(
  event = events,
  n = sample_size,
  studlab = study,
  data = data,
  sm = "PLOGIT",
  comb.fixed = FALSE,
  comb.random = TRUE,
  hakn = TRUE,
  byvar = country,       # Subgrouping variable (moderator)
  print.byvar = TRUE     # Show subgroup labels in the forest plot
)


```


**Forest plot with subgroup analysis**

```{r, echo=TRUE}
forest(meta_analysis,
       xlab = "Prevalence (95% CI)",
       leftcols = c("studlab", "event", "n"),
       leftlabs = c("Study", "Events", "Sample Size"),
       col.diamond = "blue",
       col.predict = "darkgreen",
       col.by = "black",
       print.byvar = TRUE,
       overall = TRUE,
       bylab = "Country",
       fontsize = 8)

```
